{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 8194311 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8194311it [02:13, 61446.50it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 471942 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471942it [00:06, 68785.07it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 239660 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239660it [00:03, 73053.44it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 62848 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62848it [00:00, 83024.45it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 569372 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "569372it [00:08, 70029.10it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 446313 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "446313it [00:07, 57997.44it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 3462567 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3462567it [01:11, 48357.55it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 25351935 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25351935it [11:39, 36240.61it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 24505392 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24505392it [09:37, 42442.33it/s] \n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 27553476 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27553476it [10:24, 44106.52it/s] \n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 29274876 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29274876it [09:26, 51701.85it/s] \n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 21318033 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21318033it [05:24, 65774.53it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 19349428 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19349428it [06:21, 50697.59it/s] \n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 10024077 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10024077it [03:21, 49708.66it/s]\n",
      "C:\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo: 48884994 b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29955720it [10:45, 90998.90it/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-43fbdaaef446>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnombreArchivo\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".pdf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                         \u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;31m# cStringIO doesn't like amt=None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m# do not keep args and kwds alive unnecessarily\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;31m# they are only needed for recreation, which is not possible anymore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------     SECCION DE IMPORTS       -----------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Importar BeautifulSoup y requests para poder conectarse a las páginas del SECOP\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import eventlet\n",
    "eventlet.monkey_patch()\n",
    "\n",
    "# Importar pyodbc para conectarse a bd de Azure\n",
    "import pyodbc \n",
    "\n",
    "# Importar paquete de descarga de archivos\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Importar los paquetes para poder interactuar con carpetas del S.O.\n",
    "# Y de conexión a Azure\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import sys\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------     SECCION DE FUNCIONES     -----------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Crear función que permite establecer los índices de un caracter determinado\n",
    "def findOccurrences(s, ch):\n",
    "    return [i for i, letter in enumerate(s) if letter == ch]\n",
    "\n",
    "\n",
    "# Función para cargar documentos en Azure\n",
    "def cargar_a_blob():\n",
    "    try:\n",
    "        # Crear la conexión al Servicio de Almacenamiento en Azure \"hackatonms\"\n",
    "        block_blob_service = BlockBlobService(account_name='hackaton3', account_key='qX3xaSomZIydnBsAGTNfZ/hhLugz9282RQ5qGGNe/KsVUYcgO9//3HvyWJAQlpEeXVFhxIhy+VJEWlTINxkPog==')\n",
    "\n",
    "        # Definir el contenedor donde se van a cargar todos los documentos\n",
    "        container_name ='pdf'\n",
    "\n",
    "        # Volver los permisos del contenedor públicos.\n",
    "        block_blob_service.set_container_acl(container_name, public_access=PublicAccess.Container)\n",
    "\n",
    "        # Buscar los archivos que están en la carpeta definida\n",
    "        local_path=os.path.abspath(\"../Documentos Secop/\")\n",
    "        for filename in os.listdir(local_path):\n",
    "            full_path_to_file =os.path.join(local_path, filename)\n",
    "            print(\"Temp file = \" + full_path_to_file)\n",
    "            print(\"\\nUploading to Blob storage as blob\" + filename)\n",
    "            \n",
    "            # Cargar archivo en el blob storage\n",
    "            block_blob_service.create_blob_from_path(container_name, filename, full_path_to_file)\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------  VARIALBES Y PARAMETRIZACION   ----------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Sentencia SQL para escribir en la BD\n",
    "sentenciaSQL = \"\"\n",
    "\n",
    "# Contador para los archivos\n",
    "j = 0\n",
    "\n",
    "# Conectarse a la BD hackatonms de Azure\n",
    "\n",
    "conn = pyodbc.connect(\n",
    "    r'Driver={ODBC Driver 13 for SQL Server};'\n",
    "    r'Server=sqldbserverdesafio3.database.windows.net;'\n",
    "    r'Database=SQLDB;'\n",
    "    r'UID=laura;'\n",
    "    r'PWD=Desafio3;')\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------     LÓGICA     --------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Sentencia SQL a partir de un cursor\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('SELECT DISTINCT top 5 idcontrato, url FROM dbo.contratos order by idcontrato')\n",
    "\n",
    "# Iteración sobre todos los contratos que se encuentren en la tabla\n",
    "for row in cursor:\n",
    "    # Inicializar la variable i en 1 cada vez que se tenga un contrato nuevo\n",
    "    j = 1\n",
    "    \n",
    "    # Id de contrato\n",
    "    contrato = row[0]\n",
    "    \n",
    "    # Enlace de la página a la que se le va a hacer el scrapping\n",
    "    page_link = row[1]\n",
    "    \n",
    "    # Conectarse a la página con el link determinado    \n",
    "    try:\n",
    "        with eventlet.Timeout(20):\n",
    "            page_response = requests.get(page_link, verify=False)\n",
    "        \n",
    "        page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "        \n",
    "        # Identificar todos los lugares dentro de la página donde hay información descargable.\n",
    "        \n",
    "        # Caso1: De acuerdo con la estructura, el contenedor comienza por \"a\" y el id comienta por \"lnkDocumentDownloadLink\"\n",
    "        descargable = page_content.find_all(\"a\", id=lambda value: value and value.startswith(\"lnkDocumentDownloadLink\"))\n",
    "        \n",
    "        for i in range (0,len(descargable)):\n",
    "            if len(descargable[i]) > 0:\n",
    "                # Se identifican los índices del caracter ' en la cadena de texto debido a que el substring del mínimo \n",
    "                # y máximo de estos va a permitir obtener el link de descarga del documento.\n",
    "                texto = str(descargable[i])\n",
    "                minimo = min(findOccurrences(texto,\"'\"))\n",
    "                maximo = max(findOccurrences(texto,\"'\"))\n",
    "                \n",
    "                # Substring del texto para obtener solo la parte final de la url\n",
    "                texto = texto[minimo:maximo]\n",
    "                \n",
    "                # Agregarle el inicio de la URL\n",
    "                texto = 'https://community.secop.gov.co' + texto\n",
    "                \n",
    "                # Se eliminan los caracteres que no hacen parte del link\n",
    "                texto = texto.replace(\"'\",\"\")\n",
    "                texto = texto.replace(\"+\",\"\")\n",
    "                texto = texto.replace(\" \",\"\")\n",
    "                \n",
    "                # Toma la URL de descarga y le aplica la misma metodología para llegar a la URL del PDF\n",
    "                page_response = requests.get(texto, verify=False)\n",
    "                texto2 = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "                \n",
    "                minimo = min(findOccurrences(str(texto2),\"'\"))\n",
    "                maximo = max(findOccurrences(str(texto2),\"'\"))\n",
    "                \n",
    "                # Substring del texto para obtener solo la parte final de la url\n",
    "                texto2 = str(texto2)\n",
    "                texto2 = texto2[minimo:maximo]\n",
    "                \n",
    "                # Agregarle el inicio de la URL\n",
    "                texto2 = 'https://community.secop.gov.co' + texto2\n",
    "                \n",
    "                # Se eliminan los caracteres que no hacen parte del link\n",
    "                texto2 = texto2.replace(\"'\",\"\")\n",
    "                texto2 = texto2.replace(\"+\",\"\")\n",
    "                texto2 = texto2.replace(\" \",\"\")\n",
    "                \n",
    "                # Descargar la información al disco local\n",
    "                r = requests.get(texto2)\n",
    "                print(\"Peso del archivo: \" + str(len(r.content)) + \" b.\")               \n",
    "                \n",
    "                # Solicitud HTTP de realizar la descarga\n",
    "                response = requests.get(texto2, stream=True)\n",
    "                ruta = \"../Documentos SECOP/\"\n",
    "                nombreArchivo = contrato + \"_\" + str(j)\n",
    "                \n",
    "                j = j + 1\n",
    "                # Agregar a la sentencia SQL el insert del contenido\n",
    "                sentenciaSQL += \"INSERT INTO dbo.contratos_pdf VALUES('\" + contrato + \"','Documento Contractual','\" + texto2 + \"','\"+ nombreArchivo + \".pdf');\"\n",
    "                \n",
    "                with open(ruta + nombreArchivo + \".pdf\", \"wb\") as handle:\n",
    "                    for data in tqdm(response.iter_content()):\n",
    "                        handle.write(data)\n",
    "                \n",
    "                                \n",
    "        # Caso2: De acuerdo con la estructura, el contenedor comienza por \"a\" y el id comienta por \"lnkDownloadLinkP3Gen\"\n",
    "        descargable = page_content.find_all(\"a\", id=lambda value: value and value.startswith(\"lnkDownloadLinkP3Gen\"))        \n",
    "        \n",
    "        for i in range (0,len(descargable)):\n",
    "            if len(descargable[i]) > 0:\n",
    "                # Se identifican los índices del caracter ' en la cadena de texto debido a que el substring del mínimo \n",
    "                # y máximo de estos va a permitir obtener el link de descarga del documento.\n",
    "                texto = str(descargable[i])\n",
    "                minimo = min(findOccurrences(texto,\"'\"))\n",
    "                maximo = max(findOccurrences(texto,\"'\"))\n",
    "                \n",
    "                # Substring del texto para obtener solo la parte final de la url\n",
    "                texto = texto[minimo:maximo]\n",
    "                \n",
    "                # Agregarle el inicio de la URL\n",
    "                texto = 'https://community.secop.gov.co' + texto\n",
    "                \n",
    "                # Se eliminan los caracteres que no hacen parte del link\n",
    "                texto = texto.replace(\"'\",\"\")\n",
    "                texto = texto.replace(\"+\",\"\")\n",
    "                texto = texto.replace(\" \",\"\")\n",
    "                                \n",
    "                # Toma la URL de descarga y le aplica la misma metodología para llegar a la URL del PDF\n",
    "                page_response = requests.get(texto, verify=False)\n",
    "                texto2 = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "                \n",
    "                minimo = min(findOccurrences(str(texto2),\"'\"))\n",
    "                maximo = max(findOccurrences(str(texto2),\"'\"))\n",
    "                \n",
    "                # Substring del texto para obtener solo la parte final de la url\n",
    "                texto2 = str(texto2)\n",
    "                texto2 = texto2[minimo:maximo]\n",
    "                \n",
    "                # Agregarle el inicio de la URL\n",
    "                texto2 = 'https://community.secop.gov.co' + texto2\n",
    "                \n",
    "                # Se eliminan los caracteres que no hacen parte del link\n",
    "                texto2 = texto2.replace(\"'\",\"\")\n",
    "                texto2 = texto2.replace(\"+\",\"\")\n",
    "                texto2 = texto2.replace(\" \",\"\")\n",
    "                \n",
    "                            \n",
    "                # Descargar la información al disco local\n",
    "                r = requests.get(texto2)\n",
    "                print(\"Peso del archivo: \" + str(len(r.content)) + \" b.\")               \n",
    "                \n",
    "                # Solicitud HTTP de realizar la descarga\n",
    "                response = requests.get(texto2, stream=True)\n",
    "                ruta = \"../Documentos SECOP/\"\n",
    "                nombreArchivo = contrato + \"_\" + str(j)\n",
    "                \n",
    "                j = j + 1\n",
    "                # Agregar a la sentencia SQL el insert del contenido\n",
    "                sentenciaSQL += \"INSERT INTO dbo.contratos_pdf VALUES('\" + contrato + \"','Detalle Oportunidad','\" + texto2 + \"','\"+ nombreArchivo + \".pdf');\"\n",
    "                \n",
    "                with open(ruta + nombreArchivo + \".pdf\", \"wb\") as handle:\n",
    "                    for data in tqdm(response.iter_content()):\n",
    "                        handle.write(data)\n",
    "                \n",
    "        # Caso3: De acuerdo con la estructura, el contenedor comienza por \"a\" y el id comienta por \"linkDocumentLink\"\n",
    "        descargable = page_content.find_all(\"a\", id=lambda value: value and value.startswith(\"linkDocumentLink\"))        \n",
    "        \n",
    "        for i in range (0,len(descargable)):\n",
    "            if len(descargable[i]) > 0:\n",
    "                # Se identifican los índices del caracter ' en la cadena de texto debido a que el substring del mínimo \n",
    "                # y máximo de estos va a permitir obtener el link de descarga del documento.\n",
    "                texto = str(descargable[i])\n",
    "                \n",
    "                if \"iframe\" not in texto:\n",
    "                    minimo = min(findOccurrences(texto,\"'\"))\n",
    "                    maximo = max(findOccurrences(texto,\"'\"))\n",
    "                    \n",
    "                    # Substring del texto para obtener solo la parte final de la url\n",
    "                    texto = texto[minimo:maximo]\n",
    "                    \n",
    "                    # Agregarle el inicio de la URL\n",
    "                    texto = 'https://community.secop.gov.co' + texto\n",
    "                    \n",
    "                    # Se eliminan los caracteres que no hacen parte del link\n",
    "                    texto = texto.replace(\"'\",\"\")\n",
    "                    texto = texto.replace(\"+\",\"\")\n",
    "                    texto = texto.replace(\" \",\"\")\n",
    "                    \n",
    "                    # Toma la URL de descarga y le aplica la misma metodología para llegar a la URL del PDF\n",
    "                    page_response = requests.get(texto, verify=False)\n",
    "                    texto2 = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "                    \n",
    "                    minimo = min(findOccurrences(str(texto2),\"'\"))\n",
    "                    maximo = max(findOccurrences(str(texto2),\"'\"))\n",
    "                    \n",
    "                    # Substring del texto para obtener solo la parte final de la url\n",
    "                    texto2 = str(texto2)\n",
    "                    texto2 = texto2[minimo:maximo]\n",
    "                    \n",
    "                    # Agregarle el inicio de la URL\n",
    "                    texto2 = 'https://community.secop.gov.co' + texto2\n",
    "                    \n",
    "                    # Se eliminan los caracteres que no hacen parte del link\n",
    "                    texto2 = texto2.replace(\"'\",\"\")\n",
    "                    texto2 = texto2.replace(\"+\",\"\")\n",
    "                    texto2 = texto2.replace(\" \",\"\")\n",
    "                    \n",
    "                    # Descargar la información al disco local\n",
    "                    r = requests.get(texto2)\n",
    "                    print(\"Peso del archivo: \" + str(len(r.content)) + \" b.\")               \n",
    "                    \n",
    "                    # Solicitud HTTP de realizar la descarga\n",
    "                    response = requests.get(texto2, stream=True)\n",
    "                    ruta = \"../Documentos SECOP/\"\n",
    "                    nombreArchivo = contrato + \"_\" + str(j)\n",
    "                    \n",
    "                    j = j + 1\n",
    "                    # Agregar a la sentencia SQL el insert del contenido\n",
    "                    sentenciaSQL += \"INSERT INTO dbo.contratos_pdf VALUES('\" + contrato + \"','Reporte','\" + texto2 + \"','\"+ nombreArchivo + \".pdf');\"\n",
    "                   \n",
    "                    with open(ruta + nombreArchivo + \".pdf\", \"wb\") as handle:\n",
    "                        for data in tqdm(response.iter_content()):\n",
    "                            handle.write(data)\n",
    "                                    \n",
    "    except requests.exceptions.Timeout:\n",
    "        # No hacer nada si hay una Excepción de timeout \n",
    "        print(\"error en \" & page_link )               \n",
    "        \n",
    "# Después del loop y web scrapping de todos los contratos de la tabla dbo.contratos_pdf \n",
    "# se guardan las url de los PDF que están asociados a esos contratos\n",
    "\n",
    "##cursor.execute(sentenciaSQL)\n",
    "##conn.commit()\n",
    "\n",
    "\n",
    "conn.close()\n",
    "\n",
    "cargar_a_blob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
